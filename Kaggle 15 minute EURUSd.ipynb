{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "901455c8-d5fd-4dfb-86a6-44d15a3acc6f",
    "_uuid": "cc3143d11be64e4b26d7b3e264f271f1c4ccd904"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52b27b36-fbc4-4e45-a220-c664ab6dfbc7",
    "_uuid": "3995058fb77ae366c7b3be525af2862b5007c60b"
   },
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "df = pd.read_csv('EURUSD_M12.csv',sep='\\t',encoding='utf-16')#('../input/EURUSD_15m_BID_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ec9e6dba-442c-488d-92d0-916e7b6703a2",
    "_uuid": "8f705cac308b99530a90f830e803854e7b26e595"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d381458f-2693-4d23-8d79-62fefa1e8ca6",
    "_uuid": "2c6600772d5ae8b592c9fef7f29dc93832589a7e"
   },
   "outputs": [],
   "source": [
    "df.index.min(), df.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4aaaa570-2155-4c96-9abd-78c74ed89016",
    "_uuid": "aa4d293f227bb0a3edf0faa9e277fa9ee089a517"
   },
   "outputs": [],
   "source": [
    "# FULL DATA (takes too long)\n",
    "# df = pd.read_csv('../input/EURUSD_15m_BID_01.01.2010-31.12.2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a7283d8-564f-40c4-b636-3587fa6990bf",
    "_uuid": "305dfff7460dabfae7ed2e6ac3f5f5266615d46f"
   },
   "outputs": [],
   "source": [
    "# Rename bid OHLC columns\n",
    "# df.rename(columns={'Time' : 'timestamp', 'Open' : 'open', 'Close' : 'close', \n",
    "#                    'High' : 'high', 'Low' : 'low', 'Close' : 'close', 'Volume' : 'volume'}, inplace=True)\n",
    "df.rename(columns={'Time' : 'timestamp'}, inplace=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df = df.astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1b4d74a-6137-418f-93a4-f5a2e74a359a",
    "_uuid": "cb5608ff930146ffd1c1364f9f973c867d471f7c"
   },
   "outputs": [],
   "source": [
    "# Add additional features\n",
    "df['hour'] = df.index.hour\n",
    "df['day']  = df.index.weekday\n",
    "df['week'] = df.index.week\n",
    "df['minute'] = df.index.minute\n",
    "# df['momentum']  = df['volume'] * (df['open'] - df['close'])\n",
    "df['avg_price'] = (df['low'] + df['high'])/2\n",
    "df['range']     = df['high'] - df['low']\n",
    "df['ohlc_price'] = (df['low'] + df['high'] + df['open'] + df['close'])/4\n",
    "df['oc_diff']    = df['open'] - df['close']\n",
    "\n",
    "# Cannot add ASK related features, which will limit the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d45ca935-7e02-462d-a046-8b587c7df6d8",
    "_uuid": "8f0cc48c0973272649732410963aa52a20c720eb"
   },
   "outputs": [],
   "source": [
    "# Add PCA as a feature instead of for reducing the dimensionality. This improves the accuracy a bit.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dataset = df.copy().values.astype('float32')\n",
    "pca_features = df.columns.tolist()\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "df['pca'] = pca.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7eeb62b1-a682-484b-9ba6-5b024ae28f64",
    "_uuid": "c69167f965e53056ffa92b60870793061736bc24"
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import pylab\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "norm = colors.Normalize(df['ohlc_price'].values.min(), df['ohlc_price'].values.max())\n",
    "color = cm.viridis(norm(df['ohlc_price'].values))\n",
    "plt.scatter(df['ohlc_price'].values, df['pca'].values, lw=0, c=color, cmap=pylab.cm.cool, alpha=0.3, s=1)\n",
    "plt.title('ohlc_price vs pca')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# norm = colors.Normalize(df['volume'].values.min(), df['volume'].values.max())\n",
    "# color = cm.viridis(norm(df['volume'].values))\n",
    "# plt.scatter(df['volume'].values, df['pca'].values, lw=0, c=color, cmap=pylab.cm.cool, alpha=0.3, s=1)\n",
    "# plt.title('volume vs pca')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "norm = colors.Normalize(df['ohlc_price'].values.min(), df['ohlc_price'].values.max())\n",
    "color = cm.viridis(norm(df['ohlc_price'].values))\n",
    "plt.scatter(df['ohlc_price'].shift().values, df['pca'].values, lw=0, c=color, cmap=pylab.cm.cool, alpha=0.3, s=1)\n",
    "plt.title('ohlc_price - 15min future vs pca')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# norm = colors.Normalize(df['volume'].values.min(), df['volume'].values.max())\n",
    "# color = cm.viridis(norm(df['volume'].values))\n",
    "# plt.scatter(df['volume'].shift().values, df['pca'].values, lw=0, c=color, cmap=pylab.cm.cool, alpha=0.3, s=1)\n",
    "# plt.title('volume - 15min future vs pca')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2eb47cc3-400c-4a04-bc44-9e07023b02c9",
    "_uuid": "3e329d43a6e9a833b177a765743ec9249e73c3ca"
   },
   "source": [
    "As observed above, using PCA shows data seperability that somehwat clusters the data into different price groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b20fc15f-a4b8-40f4-8796-5e21d3426680",
    "_uuid": "af5d192a1bc1c6291102c544fb77eb7c47f53f73"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "176318f8-cfd4-4830-9f63-beefad162b62",
    "_uuid": "f1688fe116bbf8663dbbf657cfe20369486d42c7"
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=20):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c8b936e0-7ad5-4c8a-8d4e-4203d85c7032",
    "_uuid": "ba4f8e7e577eb30fa512736e7824ed559d1137d9"
   },
   "source": [
    "# Doing a bit of features analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e13ad25-0da4-49cc-8362-36252ae487ce",
    "_uuid": "e3308cb07121307ce717d48b98b16af5b0abf760",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.inferno\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('Pearson correlation of features', y=1.05, size=15)\n",
    "sns.heatmap(df.corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr[corr.index == 'close'], linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2efea531-9b62-4c16-9deb-741a64c9661a",
    "_uuid": "f9a4346fd0c044ad064ed3f9b9fd87f726324a6e"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Scale and create datasets\n",
    "target_index = df.columns.tolist().index('close')\n",
    "dataset = df.values.astype('float32')\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# Set look_back to 20 which is 5 hours (15min*20)\n",
    "X, y = create_dataset(dataset, look_back=1)\n",
    "y = y[:,target_index]\n",
    "X = np.reshape(X, (X.shape[0], X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "577a77e6-4cac-4d0f-8970-17b06cb731f7",
    "_uuid": "960c97c1020c8072d2346c5afeeb1d2723f4463b"
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators = 100)\n",
    "forest = forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7f0cf340-e285-4241-955b-21f6b4119a41",
    "_uuid": "66b675557f9e0b68358219cc20a6d62a8cd198d0"
   },
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([forest.feature_importances_ for forest in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "column_list = df.columns.tolist()\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]-1):\n",
    "    print(\"%d. %s %d (%f)\" % (f, column_list[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"salmon\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b893fc2d-dbfb-4c4e-9bd4-b6577958482f",
    "_uuid": "1592f57021b81981bc5519eddd3566f9b7540ccc"
   },
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d25cb089-f944-4ce8-a415-ebef26e084a6",
    "_uuid": "97417479a9326253b1855daf84f4f6fef1b316d9"
   },
   "outputs": [],
   "source": [
    "ax = df.plot(x=df.index, y='close', c='red', figsize=(40,10))\n",
    "index = [str(item) for item in df.index]\n",
    "plt.fill_between(x=index, y1='low',y2='high', data=df, alpha=0.4)\n",
    "plt.show()\n",
    "\n",
    "p = df[:200].copy()\n",
    "ax = p.plot(x=p.index, y='close', c='red', figsize=(40,10))\n",
    "index = [str(item) for item in p.index]\n",
    "plt.fill_between(x=index, y1='low', y2='high', data=p, alpha=0.4)\n",
    "plt.title('zoomed, first 200')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff8d4234-7c71-4ade-a13a-c5c75bdc8c95",
    "_uuid": "f028f6ae47c668625c842e047a774054df9c0d46"
   },
   "outputs": [],
   "source": [
    "# Scale and create datasets\n",
    "target_index = df.columns.tolist().index('close')\n",
    "high_index = df.columns.tolist().index('high')\n",
    "low_index = df.columns.tolist().index('low')\n",
    "dataset = df.values.astype('float32')\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# Create y_scaler to inverse it later\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "t_y = df['close'].values.astype('float32')\n",
    "t_y = np.reshape(t_y, (-1, 1))\n",
    "y_scaler = y_scaler.fit(t_y)\n",
    "    \n",
    "# Set look_back to 20 which is 5 hours (15min*20)\n",
    "X, y = create_dataset(dataset, look_back=20)\n",
    "y = y[:,target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ab9d8796-dd89-4c3a-8425-e54860acf920",
    "_uuid": "31ff89b4610099a47252b518de87befa8346779f"
   },
   "outputs": [],
   "source": [
    "# Set training data size\n",
    "# We have a large enough dataset. So divid into 98% training / 1%  development / 1% test sets\n",
    "train_size = int(len(X) * 0.99)\n",
    "trainX = X[:train_size]\n",
    "trainY = y[:train_size]\n",
    "testX = X[train_size:]\n",
    "testY = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8d2615a0-32df-4998-9b83-f41d3e50ed62",
    "_uuid": "8bdd1ca1a5ad7c2e1e0fcecc7f0746ddb433933d"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input, LSTM, Dense\n",
    "\n",
    "# create a small LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(20, return_sequences=True))\n",
    "model.add(LSTM(10, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(4, return_sequences=False))\n",
    "model.add(Dense(4, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3a2e81fa-f958-4ab7-9f9d-4677148a5529",
    "_uuid": "6345784d591a2d522311dc56c8ade6c55abe569c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the best weight during training.\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"weights.best.hdf5\", monitor='val_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# Fit\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(trainX, trainY, epochs=200, batch_size=500, verbose=0, callbacks=callbacks_list, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3bd87749-6336-41f8-9e8d-28b2af668da7",
    "_uuid": "e77270be0899ae276da48515fae05303eb0d7f9b"
   },
   "outputs": [],
   "source": [
    "epoch = len(history.history['loss'])\n",
    "for k in list(history.history.keys()):\n",
    "    if 'val' not in k:\n",
    "        plt.figure(figsize=(40,10))\n",
    "        plt.plot(history.history[k])\n",
    "        plt.plot(history.history['val_' + k])\n",
    "        plt.title(k)\n",
    "        plt.ylabel(k)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90839462-0395-4116-a13b-101fc1c2bc5f",
    "_uuid": "1c73b5d4ab0969215eb3e7c18ab27e0e2545d382"
   },
   "outputs": [],
   "source": [
    "min(history.history['val_mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f2304754-a7cf-4c62-a5fe-666fec2397cf",
    "_uuid": "b8233417663b4590f6e4d378d43c3fe198bf287b"
   },
   "source": [
    "As seen from the above, the model seems to have converged nicely, but the mean absolute error on the development data remains at ~0.003X which means the model is unusable in practice. Ideally, we want to get ~0.0005. Let's go back to the best weight, and decay the learning rate while retraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5b028aca-1359-4653-9b17-fe49e31f2079",
    "_uuid": "b088bcb4e082a9c2791d414c9e16f67ff2ca959a"
   },
   "outputs": [],
   "source": [
    "# Baby the model a bit\n",
    "# Load the weight that worked the best\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "\n",
    "# Train again with decaying learning rate\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras.backend as K\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch%2==0 and epoch!=0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr*.9)\n",
    "        print(\"lr changed to {}\".format(lr*.9))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "lr_decay = LearningRateScheduler(scheduler)\n",
    "\n",
    "callbacks_list = [checkpoint, lr_decay]\n",
    "history = model.fit(trainX, trainY, epochs=int(epoch/3), batch_size=500, verbose=0, callbacks=callbacks_list, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f4b4826-71ce-4a78-8964-d3e6c8ae2cf7",
    "_uuid": "6ad515300117e7ffce8169db1afbdd296db4a04f"
   },
   "outputs": [],
   "source": [
    "epoch = len(history.history['loss'])\n",
    "for k in list(history.history.keys()):\n",
    "    if 'val' not in k:\n",
    "        plt.figure(figsize=(40,10))\n",
    "        plt.plot(history.history[k])\n",
    "        plt.plot(history.history['val_' + k])\n",
    "        plt.title(k)\n",
    "        plt.ylabel(k)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fac2ed68-5e46-4068-87bf-743287e80082",
    "_uuid": "202a1e3bb06e25b77af5029ae347bcf502dce4c2"
   },
   "outputs": [],
   "source": [
    "min(history.history['val_mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1c71e7b2-a5fa-4c96-983c-e8736f41e193",
    "_uuid": "3fbda13306965b59f682eb2d2f7604663f907e6b"
   },
   "source": [
    "The variance should have improved slightly. However, unless the mean absolute error is not small enough. The model is still not an usable model in practice. This is mainly due to only using the sample data for training and limiting epoch to a few hundreds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "862ba33b-6935-4777-b9e4-29a1fc3259b6",
    "_uuid": "70d5d8ec1b68813cf6a8cd4250da9caf2746d094"
   },
   "source": [
    "# Visually compare the delta between the prediction and actual (scaled values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "759644d5-1a1b-4916-93c5-75e9c2f5b8a2",
    "_uuid": "c9bbaade0cc059ec3e63dfabf182fcd9c3b7c885",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Benchmark\n",
    "model.load_weights(\"weights.best.hdf5\")\n",
    "\n",
    "pred = model.predict(testX)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['predicted'] = pd.Series(np.reshape(pred, (pred.shape[0])))\n",
    "predictions['actual'] = testY\n",
    "predictions = predictions.astype(float)\n",
    "\n",
    "predictions.plot(figsize=(20,10))\n",
    "plt.show()\n",
    "\n",
    "predictions['diff'] = predictions['predicted'] - predictions['actual']\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.distplot(predictions['diff']);\n",
    "plt.title('Distribution of differences between actual and prediction')\n",
    "plt.show()\n",
    "\n",
    "print(\"MSE : \", mean_squared_error(predictions['predicted'].values, predictions['actual'].values))\n",
    "print(\"MAE : \", mean_absolute_error(predictions['predicted'].values, predictions['actual'].values))\n",
    "predictions['diff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48e036a6-f1f1-4d07-aae9-40ff7b1fc34a",
    "_uuid": "90fb470b95817dc394005f294787f5a809943e26"
   },
   "source": [
    "# Compare the unscaled values and see if the prediction falls within the Low and High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c93f72cc-aff8-4e48-b022-87deab5a929e",
    "_uuid": "0cbcf799bfec016f80f0ffcfe7a66a19eedb1b7b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict(testX)\n",
    "pred = y_scaler.inverse_transform(pred)\n",
    "close = y_scaler.inverse_transform(np.reshape(testY, (testY.shape[0], 1)))\n",
    "predictions = pd.DataFrame()\n",
    "predictions['predicted'] = pd.Series(np.reshape(pred, (pred.shape[0])))\n",
    "predictions['close'] = pd.Series(np.reshape(close, (close.shape[0])))\n",
    "\n",
    "p = df[-pred.shape[0]:].copy()\n",
    "predictions.index = p.index\n",
    "predictions = predictions.astype(float)\n",
    "predictions = predictions.merge(p[['low', 'high']], right_index=True, left_index=True)\n",
    "\n",
    "ax = predictions.plot(x=predictions.index, y='close', c='red', figsize=(40,10))\n",
    "ax = predictions.plot(x=predictions.index, y='predicted', c='blue', figsize=(40,10), ax=ax)\n",
    "index = [str(item) for item in predictions.index]\n",
    "plt.fill_between(x=index, y1='low', y2='high', data=p, alpha=0.4)\n",
    "plt.title('Prediction vs Actual (low and high as blue region)')\n",
    "plt.show()\n",
    "\n",
    "predictions['diff'] = predictions['predicted'] - predictions['close']\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.distplot(predictions['diff']);\n",
    "plt.title('Distribution of differences between actual and prediction ')\n",
    "plt.show()\n",
    "\n",
    "g = sns.jointplot(\"diff\", \"predicted\", data=predictions, kind=\"kde\", space=0)\n",
    "plt.title('Distributtion of error and price')\n",
    "plt.show()\n",
    "\n",
    "# predictions['correct'] = (predictions['predicted'] <= predictions['high']) & (predictions['predicted'] >= predictions['low'])\n",
    "# sns.factorplot(data=predictions, x='correct', kind='count')\n",
    "\n",
    "print(\"MSE : \", mean_squared_error(predictions['predicted'].values, predictions['close'].values))\n",
    "print(\"MAE : \", mean_absolute_error(predictions['predicted'].values, predictions['close'].values))\n",
    "predictions['diff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "935ca5504302a194d0af986410681213ea3fe5bc"
   },
   "source": [
    "The above references an opinion and is for information purposes only.  It is not intended to be investment advice.  Seek a duly licensed professional for investment advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX,testY)\n",
    "print(score[0])\n",
    "print(score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='jafferwilson', api_key='EkP7ePXHyQaUZxPIX2Zv')\n",
    "trace = go.Candlestick(x=predictions.index,\n",
    "                       open=predictions.predicted,\n",
    "                       high=predictions.high,\n",
    "                       low=predictions.low,\n",
    "                       close=predictions.close)\n",
    "data = [trace]\n",
    "py.iplot(data, filename='simple_candlestick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testX)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['predicted'] = pd.Series(np.reshape(pred, (pred.shape[0])))\n",
    "predictions['actual'] = testY\n",
    "predictions = predictions.astype(float)\n",
    "\n",
    "predictions.plot(figsize=(20,10))\n",
    "plt.show()\n",
    "\n",
    "predictions['diff'] = predictions['predicted'] - predictions['actual']\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.distplot(predictions['diff']);\n",
    "plt.title('Distribution of differences between actual and prediction')\n",
    "plt.show()\n",
    "\n",
    "print(\"MSE : \", mean_squared_error(predictions['predicted'].values, predictions['actual'].values))\n",
    "print(\"MAE : \", mean_absolute_error(predictions['predicted'].values, predictions['actual'].values))\n",
    "predictions['diff'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
